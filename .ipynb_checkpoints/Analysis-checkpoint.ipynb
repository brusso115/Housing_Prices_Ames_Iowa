{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import math\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from regressors import stats\n",
    "from scipy.stats import kurtosis, skew, boxcox\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',index_col='Id')\n",
    "test = pd.read_csv('test.csv',index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      259\n",
       "Alley           1369\n",
       "MasVnrType         8\n",
       "MasVnrArea         8\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtFinType2      38\n",
       "Electrical         1\n",
       "FireplaceQu      690\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "PoolQC          1453\n",
       "Fence           1179\n",
       "MiscFeature     1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_counts_train = train.isnull().sum()\n",
    "na_counts_train[na_counts_train != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning           4\n",
       "LotFrontage      227\n",
       "Alley           1352\n",
       "Utilities          2\n",
       "Exterior1st        1\n",
       "Exterior2nd        1\n",
       "MasVnrType        16\n",
       "MasVnrArea        15\n",
       "BsmtQual          44\n",
       "BsmtCond          45\n",
       "BsmtExposure      44\n",
       "BsmtFinType1      42\n",
       "BsmtFinSF1         1\n",
       "BsmtFinType2      42\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "TotalBsmtSF        1\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "KitchenQual        1\n",
       "Functional         2\n",
       "FireplaceQu      730\n",
       "GarageType        76\n",
       "GarageYrBlt       78\n",
       "GarageFinish      78\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "GarageQual        78\n",
       "GarageCond        78\n",
       "PoolQC          1456\n",
       "Fence           1169\n",
       "MiscFeature     1408\n",
       "SaleType           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_counts_test = test.isnull().sum()\n",
    "na_counts_test[na_counts_test != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \n",
    "    def __init__(self, train, test):\n",
    "        self.train = train.copy()\n",
    "        self.test = test.copy()\n",
    "        \n",
    "    \n",
    "    def cleanAlley(self):\n",
    "        self.train.loc[:,'Alley'] = self.train['Alley'].fillna('No_Alley_Access')\n",
    "        self.test.loc[:,'Alley'] = self.test['Alley'].fillna('No_Alley_Access')\n",
    "    \n",
    "    \n",
    "    def cleanBsmt(self):\n",
    "        self.cleanBsmtQual()\n",
    "        self.cleanBsmtCond()\n",
    "        self.cleanBsmtExposure()\n",
    "        self.cleanBsmtFinType1()\n",
    "        self.cleanBsmtFinType2()\n",
    "        self.cleanBsmtFinSF1()\n",
    "        self.cleanBsmtFinSF2()\n",
    "        self.cleanBsmtUnfSF()\n",
    "        self.cleanTotalBsmtSF()\n",
    "        self.cleanBsmtFullBath()\n",
    "        self.cleanBsmtHalfBath()\n",
    "    \n",
    "    def cleanBsmtQual(self):\n",
    "        self.train.loc[:,'BsmtQual'] = self.train['BsmtQual'].fillna('No_Basement')\n",
    "        self.test.loc[:,'BsmtQual'] = self.test['BsmtQual'].fillna('No_Basement')\n",
    "        \n",
    "        \n",
    "    def cleanBsmtCond(self):\n",
    "        self.train.loc[:,'BsmtCond'] = self.train['BsmtCond'].fillna('No_Basement')\n",
    "        self.test.loc[:,'BsmtCond'] = self.test['BsmtCond'].fillna('No_Basement')\n",
    "        \n",
    "    \n",
    "    def cleanBsmtExposure(self):\n",
    "        self.train.loc[:,'BsmtExposure'] = self.train['BsmtExposure'].fillna('No_Basement')\n",
    "        self.test.loc[:,'BsmtExposure'] = self.test['BsmtExposure'].fillna('No_Basement')\n",
    "        \n",
    "        \n",
    "    def cleanBsmtFinType1(self):\n",
    "        self.train.loc[:,'BsmtFinType1'] = self.train['BsmtFinType1'].fillna('No_Basement')\n",
    "        self.test.loc[:,'BsmtFinType1'] = self.test['BsmtFinType1'].fillna('No_Basement')\n",
    "\n",
    "        \n",
    "    def cleanBsmtFinType2(self):\n",
    "        self.train.loc[:,'BsmtFinType2'] = self.train['BsmtFinType2'].fillna('No_Basement')\n",
    "        self.test.loc[:,'BsmtFinType2'] = self.test['BsmtFinType2'].fillna('No_Basement')\n",
    "        \n",
    "        \n",
    "    def cleanBsmtFinSF1(self):\n",
    "\n",
    "        self.train.loc[:,'BsmtFinSF1'] = self.train['BsmtFinSF1'].fillna(0)\n",
    "        self.test.loc[:,'BsmtFinSF1'] = self.test['BsmtFinSF1'].fillna(0)\n",
    "\n",
    "        \n",
    "    def cleanBsmtFinSF2(self):\n",
    "        self.train.loc[:,'BsmtFinSF2'] = self.train['BsmtFinSF2'].fillna(0)\n",
    "        self.test.loc[:,'BsmtFinSF2'] = self.test['BsmtFinSF2'].fillna(0)\n",
    "        \n",
    "\n",
    "    def cleanBsmtUnfSF(self):\n",
    "        self.train.loc[:,'BsmtUnfSF'] = self.train['BsmtUnfSF'].fillna(0)\n",
    "        self.test.loc[:,'BsmtUnfSF'] = self.test['BsmtUnfSF'].fillna(0)\n",
    "        \n",
    "        \n",
    "    def cleanTotalBsmtSF(self):\n",
    "        self.train.loc[:,'TotalBsmtSF'] = self.train['TotalBsmtSF'].fillna(0)   \n",
    "        self.test.loc[:,'TotalBsmtSF'] = self.test['TotalBsmtSF'].fillna(0)\n",
    "        \n",
    "        \n",
    "    def cleanBsmtFullBath(self):\n",
    "        self.train.loc[:,'BsmtFullBath'] = self.train['BsmtFullBath'].fillna(0)\n",
    "        self.test.loc[:,'BsmtFullBath'] = self.test['BsmtFullBath'].fillna(0)\n",
    "        \n",
    "    def cleanBsmtHalfBath(self):\n",
    "        self.train.loc[:,'BsmtHalfBath'] = self.train['BsmtHalfBath'].fillna(0)\n",
    "        self.test.loc[:,'BsmtHalfBath'] = self.test['BsmtHalfBath'].fillna(0)\n",
    "    \n",
    "    \n",
    "    def cleanFireplaceQu(self):\n",
    "        self.train.loc[:,'FireplaceQu'] = self.train['FireplaceQu'].fillna('No_Fireplace')\n",
    "        self.test.loc[:,'FireplaceQu'] = self.test['FireplaceQu'].fillna('No_Fireplace')\n",
    "    \n",
    "    \n",
    "    def cleanGarage(self):\n",
    "        self.cleanGarageType()\n",
    "        self.cleanGarageYrBlt()\n",
    "        self.cleanGarageFinish()\n",
    "        self.cleanGarageQual()\n",
    "        self.cleanGarageCond()\n",
    "        self.cleanGarageCars()\n",
    "        self.cleanGarageArea()\n",
    "        \n",
    "        \n",
    "    def cleanGarageType(self):\n",
    "        self.train.loc[:,'GarageType'] = self.train['GarageType'].fillna('No_Garage')\n",
    "        self.test.loc[:,'GarageType'] = self.test['GarageType'].fillna('No_Garage')\n",
    "        \n",
    "        \n",
    "    def cleanGarageYrBlt(self):\n",
    "        self.train.loc[:,'GarageYrBlt'] = self.train['GarageYrBlt'].fillna(0)\n",
    "        self.test.loc[:,'GarageYrBlt'] = self.test['GarageYrBlt'].fillna(0)\n",
    "\n",
    "        \n",
    "    def cleanGarageFinish(self):\n",
    "        self.train.loc[:,'GarageFinish'] = self.train['GarageFinish'].fillna('No_Garage')\n",
    "        self.test.loc[:,'GarageFinish'] = self.test['GarageFinish'].fillna('No_Garage')\n",
    "        \n",
    "        \n",
    "    def cleanGarageQual(self):\n",
    "        self.train.loc[:,'GarageQual'] = self.train['GarageQual'].fillna('No_Garage')        \n",
    "        self.test.loc[:,'GarageQual'] = self.test['GarageQual'].fillna('No_Garage')\n",
    "        \n",
    "          \n",
    "    def cleanGarageCond(self):\n",
    "        self.train.loc[:,'GarageCond'] = self.train['GarageCond'].fillna('No_Garage')        \n",
    "        self.test.loc[:,'GarageCond'] = self.test['GarageCond'].fillna('No_Garage')\n",
    "        \n",
    "        \n",
    "    def cleanGarageCars(self):\n",
    "        self.train.loc[:,'GarageCars'] = self.train['GarageCars'].fillna(0)        \n",
    "        self.test.loc[:,'GarageCars'] = self.test['GarageCars'].fillna(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def cleanGarageArea(self):\n",
    "        self.train.loc[:,'GarageArea'] = self.train['GarageArea'].fillna(0)        \n",
    "        self.test.loc[:,'GarageArea'] = self.test['GarageArea'].fillna(0)\n",
    "        \n",
    "        \n",
    "    def cleanPoolQC(self):\n",
    "        self.train.loc[:,'PoolQC'] = self.train['PoolQC'].fillna('No_Pool')\n",
    "        self.test.loc[:,'PoolQC'] = self.test['PoolQC'].fillna('No_Pool')\n",
    "    \n",
    "    \n",
    "    def cleanFence(self):\n",
    "        self.train.loc[:,'Fence'] = self.train['Fence'].fillna('No_Fence')\n",
    "        self.test.loc[:,'Fence'] = self.test['Fence'].fillna('No_Fence')\n",
    "\n",
    "    \n",
    "    def cleanMiscFeature(self):\n",
    "        self.train.loc[:,'MiscFeature'] = self.train['MiscFeature'].fillna('No_Misc_Feature')\n",
    "        self.test.loc[:,'MiscFeature'] = self.test['MiscFeature'].fillna('No_Misc_Feature')\n",
    "        \n",
    "        \n",
    "    def cleanMasVnrType(self):\n",
    "        #self.imputeColumn('MasVnrType')\n",
    "        self.train.loc[:,'MasVnrType'] = self.train['MasVnrType'].fillna('No_MasVnr')\n",
    "        self.test.loc[:,'MasVnrType'] = self.test['MasVnrType'].fillna('No_MasVnr')\n",
    "\n",
    "        \n",
    "    \n",
    "    def cleanMasVnrArea(self):\n",
    "        #self.imputeColumn('MasVnrArea')\n",
    "        self.train.loc[:,'MasVnrArea'] = self.train['MasVnrArea'].fillna(0)\n",
    "        self.test.loc[:,'MasVnrArea'] = self.test['MasVnrArea'].fillna(0)\n",
    "        \n",
    "        \n",
    "    def cleanMSSubClass(self):\n",
    "        self.train.loc[:,'MSSubClass'] = self.train['MSSubClass'].astype('object')\n",
    "        self.test.loc[:,'MSSubClass'] = self.test['MSSubClass'].astype('object')\n",
    "\n",
    "\n",
    "    \n",
    "    def cleanLotFrontage(self):\n",
    "         self.imputeColumn('LotFrontage')\n",
    "        \n",
    "        \n",
    "    def cleanElectrical(self):\n",
    "        self.imputeColumn('Electrical')\n",
    "        \n",
    "        \n",
    "    def cleanMSZoning(self):\n",
    "        self.imputeColumn('MSZoning')\n",
    "        \n",
    "    def cleanUtilities(self):\n",
    "        self.imputeColumn('Utilities')\n",
    "        \n",
    "        \n",
    "    def cleanExterior1st(self):\n",
    "        self.imputeColumn('Exterior1st')\n",
    "        \n",
    "    def cleanExterior2nd(self):\n",
    "        self.imputeColumn('Exterior2nd')\n",
    "        \n",
    "    def cleanKitchenQual(self):\n",
    "        self.imputeColumn('KitchenQual')\n",
    "        \n",
    "        \n",
    "    def cleanFunctional(self):\n",
    "        self.imputeColumn('Functional')\n",
    "        \n",
    "        \n",
    "    def cleanSaleType(self):\n",
    "        self.imputeColumn('SaleType')\n",
    "        \n",
    "        \n",
    "    def imputeColumn(self, colName):\n",
    "        train, test = self.dummify([colName])\n",
    "        missing_train = train[train[colName].isnull()]\n",
    "        train_na = train[train[colName].notnull()]\n",
    "        missing_test = test[test[colName].isnull()]\n",
    "        \n",
    "        isMissingFeatureCol_Train = sum(missing_train.columns[missing_train.isnull().sum() != 0] != colName) == 0\n",
    "        isMissingFeatureCol_Test = sum(missing_test.columns[missing_test.isnull().sum() != 0] != colName) == 0\n",
    "\n",
    "        if (isMissingFeatureCol_Train) & (isMissingFeatureCol_Test):\n",
    "            print('Dropping Rows')\n",
    "            train_na = train[train[colName].notnull()]\n",
    "            train_na = train_na.dropna()\n",
    "            train_na_X = train_na.loc[:,train_na.columns.difference([colName,'SalePrice'])]\n",
    "            train_na_y = train_na[colName]\n",
    "            \n",
    "            missing_train = missing_train.loc[:,missing_train.columns.difference([colName, 'SalePrice'])]\n",
    "            missing_test = missing_test.loc[:,missing_test.columns.difference([colName, 'SalePrice'])]\n",
    "             \n",
    "            rf = self.randomForestImputation(train_na_X, train_na_y, train[colName].dtypes, 2)\n",
    "                \n",
    "            \n",
    "            if len(missing_train) != 0:\n",
    "                imputed = rf.predict(missing_train)\n",
    "                m = self.train[colName].isnull()\n",
    "                self.train.loc[m, colName] = imputed\n",
    "                \n",
    "            if len(missing_test) != 0:\n",
    "                imputed = rf.predict(missing_test)\n",
    "                m = self.test[colName].isnull()\n",
    "                self.test.loc[m, colName] = imputed  \n",
    "        else:\n",
    "            print('DroppingCols')\n",
    "            colsWithNA = train_na.columns[train_na.isnull().sum() != 0].to_list()\n",
    "            colsWithNA_Missing = missing_train.columns[missing_train.isnull().sum() != 0].to_list()\n",
    "            targetCols = [colName,'SalePrice']\n",
    "            colsToDrop = targetCols + colsWithNA + colsWithNA_Missing\n",
    "\n",
    "            train_na_X = train_na.loc[:,train_na.columns.difference(colsToDrop)]\n",
    "            train_na_y = train_na[colName]\n",
    "\n",
    "            missing_train = missing_train.loc[:,missing_train.columns.difference(colsToDrop)]\n",
    "            missing_test = missing_test.loc[:,missing_test.columns.difference(colsToDrop)]\n",
    "            \n",
    "            rf = self.randomForestImputation(train_na_X, train_na_y, train[colName].dtypes, 2)\n",
    "        \n",
    "            if len(missing_train) != 0:\n",
    "                imputed = rf.predict(missing_train)\n",
    "                m = self.train[colName].isnull()\n",
    "                self.train.loc[m, colName] = imputed\n",
    "                \n",
    "            if len(missing_test) != 0:\n",
    "                imputed = rf.predict(missing_test)\n",
    "                m = self.test[colName].isnull()\n",
    "                self.test.loc[m, colName] = imputed\n",
    "                \n",
    "    def randomForestImputation(self, train_X, train_y, forestType, cv):\n",
    "        \n",
    "        if forestType == 'object':\n",
    "            rf = RandomForestClassifier()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "            predictions = rf.predict(X_test)\n",
    "            print(confusion_matrix(predictions, y_test))\n",
    "            print(accuracy_score(predictions, y_test))\n",
    "            print(precision_score(predictions, y_test, average='weighted'))\n",
    "            \n",
    "        else:\n",
    "            rf = RandomForestRegressor()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "            predictions = rf.predict(X_test)\n",
    "            print(pd.DataFrame(predictions,y_test))\n",
    "            print(mean_squared_error(predictions, y_test))\n",
    "        \n",
    "        return rf\n",
    "            \n",
    "    '''\n",
    "    def cleanAllColumns(self):\n",
    "        self.cleanAlley()\n",
    "        self.cleanBsmt()\n",
    "        self.cleanElectrical()\n",
    "        self.cleanFence()\n",
    "        self.cleanFireplaceQu()\n",
    "        self.cleanGarage()\n",
    "        self.cleanMasVnrArea()\n",
    "        self.cleanMasVnrType()\n",
    "        self.cleanMiscFeature()\n",
    "        self.cleanPoolQC()\n",
    "        self.cleanMSZoning()\n",
    "        self.cleanUtilities()\n",
    "        self.cleanExterior1st()\n",
    "        self.cleanExterior2nd()\n",
    "        self.cleanKitchenQual()\n",
    "        self.cleanFunctional()\n",
    "        self.cleanSaleType()   \n",
    "    '''\n",
    "\n",
    "        \n",
    "    def dummify(self, notCols):\n",
    "        cat_cols = self.train.dtypes[self.train.dtypes == 'object'].index.to_list()\n",
    "        \n",
    "        try:\n",
    "            for col in notCols:\n",
    "                cat_cols.remove(col)\n",
    "        except:\n",
    "            print('Column not in category cols')\n",
    "        \n",
    "        dum_train = pd.DataFrame()\n",
    "        dum_test = pd.DataFrame()\n",
    "        dummies_train = []\n",
    "        dummies_test = []\n",
    "        for col in cat_cols:\n",
    "            dum_train = pd.get_dummies(self.train[col], prefix=f'{col}Dummy', drop_first=True)\n",
    "            dum_test = pd.get_dummies(self.test[col], prefix= f'{col}Dummy', drop_first=True)\n",
    "            dummies_train.append(dum_train)\n",
    "            dummies_test.append(dum_test)\n",
    "            \n",
    "        \n",
    "        concat_dummies_train = pd.concat(dummies_train, axis=1)\n",
    "        train = pd.concat([self.train, concat_dummies_train], axis=1)\n",
    "        train = train.drop(cat_cols, axis=1)\n",
    "       \n",
    "        concat_dummies_test = pd.concat(dummies_test, axis=1)\n",
    "        test = pd.concat([self.test, concat_dummies_test],axis=1)\n",
    "        test = test.drop(cat_cols, axis=1)\n",
    "        \n",
    "        missingCols = set(train.columns) - set(test.columns)\n",
    "        for col in missingCols:\n",
    "            if col != 'SalePrice':\n",
    "                test[col] = 0\n",
    "                \n",
    "        \n",
    "        missingCols = set(test.columns) - set(train.columns)        \n",
    "        for col in missingCols:\n",
    "            train[col] = 0\n",
    "            \n",
    "\n",
    "        return [train, test]\n",
    "    \n",
    "    \n",
    "    def ordinalEncode(self, ordCols):\n",
    "\n",
    "        full = pd.concat([self.train[ordCols], self.test[ordCols]],axis=0)\n",
    "        \n",
    "        ordEnc = OrdinalEncoder()\n",
    "        ordEnc.fit(full)\n",
    "        self.train[ordCols] = ordEnc.transform(self.train[ordCols])\n",
    "        self.test[ordCols] = ordEnc.transform(self.test[ordCols])        \n",
    "        \n",
    "    def getCategoryColumns(self):\n",
    "        catColsTrain = self.train.columns[self.train.dtypes == 'object']\n",
    "        catColsTest = self.test.columns[self.test.dtypes == 'object']\n",
    "        \n",
    "        return [catColsTrain, catColsTest]\n",
    "    \n",
    "    def getNumericColumns(self):\n",
    "        numColsTrain = self.train.columns[self.train.dtypes != 'object']\n",
    "        numColsTest = self.test.columns[self.test.dtypes != 'object']\n",
    "        \n",
    "        return [numColsTrain, numColsTest]\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Rows\n",
      "[[  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [ 18   5   1 216]]\n",
      "0.9\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cleaned = DataCleaner(train, test)\n",
    "cleaned.cleanAlley()\n",
    "cleaned.cleanBsmtQual()\n",
    "cleaned.cleanBsmtCond()\n",
    "cleaned.cleanBsmtExposure()\n",
    "cleaned.cleanBsmtFinType1()\n",
    "cleaned.cleanBsmtFinType2()\n",
    "cleaned.cleanBsmtFinSF1()\n",
    "cleaned.cleanBsmtFinSF2()\n",
    "cleaned.cleanBsmtUnfSF()\n",
    "cleaned.cleanMasVnrType()\n",
    "cleaned.cleanMasVnrArea()\n",
    "cleaned.cleanTotalBsmtSF()\n",
    "cleaned.cleanBsmtHalfBath()\n",
    "cleaned.cleanBsmtFullBath()\n",
    "cleaned.cleanFireplaceQu()\n",
    "cleaned.cleanGarageType()\n",
    "cleaned.cleanGarageYrBlt()\n",
    "cleaned.cleanGarageFinish()\n",
    "cleaned.cleanGarageQual()\n",
    "cleaned.cleanGarageFinish()\n",
    "cleaned.cleanGarageQual()\n",
    "cleaned.cleanGarageCond()\n",
    "cleaned.cleanGarageCars()\n",
    "cleaned.cleanGarageArea()\n",
    "cleaned.cleanPoolQC()\n",
    "cleaned.cleanFence()\n",
    "cleaned.cleanMiscFeature()\n",
    "cleaned.cleanMSSubClass()\n",
    "cleaned.cleanElectrical()\n",
    "cleaned.cleanMSZoning()\n",
    "cleaned.cleanUtilities()\n",
    "cleaned.cleanExterior1st()\n",
    "cleaned.cleanExterior2nd()\n",
    "cleaned.cleanKitchenQual()\n",
    "cleaned.cleanFunctional()\n",
    "cleaned.cleanSaleType()\n",
    "cleaned.cleanLotFrontage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCatCols, testCatCols = cleaned.getCategoryColumns()\n",
    "trainNumCols, testNumCols = cleaned.getNumericColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistograms(cols, data):\n",
    "    f, axes = plt.subplots(round(len(cols)/2)+1, 2, figsize=(10,80))\n",
    "    rowIdx = 0\n",
    "    colIdx = 0\n",
    "    for col in cols:\n",
    "        if colIdx > 1:\n",
    "            rowIdx = rowIdx + 1\n",
    "            colIdx = 0\n",
    "            \n",
    "        if col == 'GarageYrBlt':\n",
    "            continue\n",
    "        #print(rowIdx,colIdx)\n",
    "        ax = sns.histplot(x=col, data=cleaned.train, ax=axes[rowIdx,colIdx]).set_title(col)\n",
    "        data[col].value_counts()\n",
    "        colIdx += 1\n",
    "    f.tight_layout()\n",
    "    \n",
    "def getBoxplots(cols, data):\n",
    "    f, axes = plt.subplots(round(len(cols)/2)+1, 2, figsize=(10,80))\n",
    "    rowIdx = 0\n",
    "    colIdx = 0\n",
    "    for col in cols:\n",
    "        if colIdx > 1:\n",
    "            rowIdx = rowIdx + 1\n",
    "            colIdx = 0\n",
    "        #print(rowIdx,colIdx)\n",
    "        if col == 'GarageYrBlt':\n",
    "            continue\n",
    "        ax = sns.boxplot(x=col, y='SalePrice', data=cleaned.train, ax=axes[rowIdx,colIdx]).set_title(col)\n",
    "        data[col].value_counts()\n",
    "        colIdx += 1\n",
    "    f.tight_layout()\n",
    "    \n",
    "    \n",
    "def getScatterplots(cols, data):\n",
    "    f, axes = plt.subplots(round(len(cols)/2)+1, 2, figsize=(10,80))\n",
    "    rowIdx = 0\n",
    "    colIdx = 0\n",
    "    for col in cols:\n",
    "        if colIdx > 1:\n",
    "            rowIdx = rowIdx + 1\n",
    "            colIdx = 0\n",
    "        if col == 'GarageYrBlt':\n",
    "            continue\n",
    "        #print(rowIdx,colIdx)\n",
    "        ax = sns.scatterplot(x=col, y='SalePrice', data=cleaned.train, ax=axes[rowIdx,colIdx]).set_title(col)\n",
    "        colIdx += 1\n",
    "    f.tight_layout()\n",
    "    \n",
    "    \n",
    "def getValueCounts(cols, data):\n",
    "    f, axes = plt.subplots(round(len(cols)/2)+1, 2, figsize=(10,80))\n",
    "    rowIdx = 0\n",
    "    colIdx = 0\n",
    "    for col in cols:\n",
    "        if colIdx > 1:\n",
    "            rowIdx = rowIdx + 1\n",
    "            colIdx = 0\n",
    "        value_counts = data[col].value_counts()\n",
    "        ax = sns.barplot(x=value_counts.index, y=value_counts, data=cleaned.train, ax=axes[rowIdx,colIdx]).set_title(col)\n",
    "        colIdx += 1\n",
    "    f.tight_layout()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getBoxplots(trainCatCols, cleaned.train)\n",
    "getValueCounts(trainCatCols, cleaned.train)\n",
    "getScatterplots(trainNumCols, cleaned.train)\n",
    "getHistograms(cleaned.train.columns, cleaned.train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getBoxplots(testCatCols, cleaned.test)\n",
    "getValueCounts(testCatCols, cleaned.test)\n",
    "getScatterplots(testNumCols, cleaned.test)\n",
    "getHistograms(cleaned.test.columns, cleaned.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "outliers.append(cleaned.train[cleaned.train['TotalBsmtSF'] > 6000].index.to_list())\n",
    "outliers.append(cleaned.train[cleaned.train['1stFlrSF'] > 4000].index.to_list())\n",
    "outliers.append(cleaned.train[(cleaned.train['GrLivArea'] > 4000) & (cleaned.train['SalePrice'] < 300000)].index.to_list())\n",
    "outliers.append(cleaned.train[cleaned.train['BsmtFinSF1'] > 4000].index.to_list())\n",
    "outliers.append(cleaned.train[cleaned.train['LotFrontage'] > 300].index.to_list())\n",
    "outliers.append(cleaned.train[cleaned.train['LotArea'] > 100000].index.to_list())\n",
    "outliers.append(cleaned.train[(cleaned.train['GarageArea'] > 1200) & (cleaned.train['SalePrice'] < 300000)].index.to_list())\n",
    "#outliers = np.array(outliers)\n",
    "outliers = [item for sublist in outliers for item in sublist]\n",
    "outliers = list(set(outliers))\n",
    "\n",
    "cleaned.train = cleaned.train[~cleaned.train.index.isin(outliers)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHasGarage(data):\n",
    "    data['hasGarage'] = data['GarageType'].apply(lambda x: 0 if x=='No_Garage' else 1)\n",
    "\n",
    "    \n",
    "def addHasBsmt(data): \n",
    "    data['hasBsmt'] = data['BsmtQual'].apply(lambda x: 0 if x=='No_Basement' else 1)\n",
    "    \n",
    "def addHasAlley_Access(data): \n",
    "    data['hasAlley_Access'] = data['Alley'].apply(lambda x: 0 if x=='No_Alley_Access' else 1)\n",
    "    \n",
    "def addHasFireplace(data):\n",
    "    data['hasFireplace'] = data['FireplaceQu'].apply(lambda x: 0 if x=='No_Fireplace' else 1)\n",
    "    \n",
    "def addHasPool(data):\n",
    "    data['hasPool'] = data['PoolQC'].apply(lambda x: 0 if x=='No_Pool' else 1)\n",
    "\n",
    "    \n",
    "def addHasFence(data): \n",
    "    data['hasFence'] = data['Fence'].apply(lambda x: 0 if x=='No_Fence' else 1)\n",
    "\n",
    "    \n",
    "def addHasMisc_Feature(data):\n",
    "    data['hasMisc_Feature'] = data['MiscFeature'].apply(lambda x: 0 if x=='No_Misc_Feature' else 1)\n",
    "    \n",
    "    \n",
    "def addHasMasVnr(data):\n",
    "    data['hasMasVnr'] = data['MasVnrType'].apply(lambda x: 0 if x=='No_MasVnr' else 1)\n",
    "\n",
    "    \n",
    "def getNumFloors(row):\n",
    "    count = 0\n",
    "    if row['TotalBsmtSF'] != 0:\n",
    "        count = count + 1\n",
    "    if row['1stFlrSF'] != 0:\n",
    "        count = count + 1\n",
    "    if row['2ndFlrSF'] != 0:\n",
    "        count = count + 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def addGrLivAreaHighQualitySF(data):\n",
    "    data['GrLivAreaHighQualitySF'] = (data['1stFlrSF'] + data['2ndFlrSF']) - data['LowQualFinSF']\n",
    "    \n",
    "def addTotalIndoorSF(data):\n",
    "    data['TotalIndoorSF'] = data['TotalBsmtSF'] + data['GrLivAreaHighQualitySF'] + data['GarageArea']\n",
    "\n",
    "def addTotalOutdoorSF(data):\n",
    "    data['TotalOutdoorSF'] = data['OpenPorchSF'] + data['EnclosedPorch'] + data['3SsnPorch'] + data['ScreenPorch'] \n",
    "    + data['WoodDeckSF'] + data['PoolArea']\n",
    "    \n",
    "\n",
    "def addBsmtBaths(data):\n",
    "    data['BsmtBaths'] = data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath'])\n",
    "\n",
    "def addBaths(data):\n",
    "    data['Baths'] = data['FullBath'] + (0.5 * data['HalfBath'])\n",
    "    \n",
    "def addHasBeenRemodeled(data):\n",
    "    data['hasBeenRemodeled'] = data.apply(lambda x: 0 if x['YearBuilt'] == x['YearRemodAdd'] else 1, axis=1)\n",
    "\n",
    "    \n",
    "def plotIndicators(data):\n",
    "    f, axes = plt.subplots(9,1, figsize=(10,30))\n",
    "    cols = ['Garage', 'Bsmt', 'Alley_Access','Fireplace', 'Pool', 'Fence', 'Misc_Feature', 'MasVnr', 'BeenRemodeled']\n",
    "\n",
    "    \n",
    "    for idx, col in enumerate(cols):\n",
    "        grouped_garage = data.groupby(f'has{col}').mean().reset_index()\n",
    "        ax = sns.barplot(grouped_garage[f'has{col}'],grouped_garage['SalePrice'], ax = axes[idx])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addHasGarage(cleaned.train)\n",
    "addHasGarage(cleaned.test)\n",
    "\n",
    "addHasBsmt(cleaned.train)\n",
    "addHasBsmt(cleaned.test)\n",
    "\n",
    "addHasAlley_Access(cleaned.train)\n",
    "addHasAlley_Access(cleaned.test)\n",
    "\n",
    "addHasFireplace(cleaned.train)\n",
    "addHasFireplace(cleaned.test)\n",
    "\n",
    "addHasPool(cleaned.train)\n",
    "addHasPool(cleaned.test)\n",
    "\n",
    "addHasFence(cleaned.train)\n",
    "addHasFence(cleaned.test)\n",
    "\n",
    "addHasMisc_Feature(cleaned.train)\n",
    "addHasMisc_Feature(cleaned.test)\n",
    "\n",
    "\n",
    "addHasMasVnr(cleaned.train)\n",
    "addHasMasVnr(cleaned.test)\n",
    "\n",
    "\n",
    "addGrLivAreaHighQualitySF(cleaned.train)\n",
    "addGrLivAreaHighQualitySF(cleaned.test)\n",
    "\n",
    "\n",
    "addTotalIndoorSF(cleaned.train)\n",
    "addTotalIndoorSF(cleaned.test)\n",
    "\n",
    "\n",
    "addTotalOutdoorSF(cleaned.train)\n",
    "addTotalOutdoorSF(cleaned.test)\n",
    "\n",
    "\n",
    "addBsmtBaths(cleaned.train)\n",
    "addBsmtBaths(cleaned.test)\n",
    "\n",
    "\n",
    "addBaths(cleaned.train)\n",
    "addBaths(cleaned.test)\n",
    "\n",
    "\n",
    "addHasBeenRemodeled(cleaned.train)\n",
    "addHasBeenRemodeled(cleaned.test)\n",
    "\n",
    "cleaned.train['NumFloors'] = cleaned.train.apply(getNumFloors, axis=1)\n",
    "cleaned.test['NumFloors'] = cleaned.test.apply(getNumFloors, axis=1)\n",
    "\n",
    "plotIndicators(cleaned.train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToDrop = ['PoolArea','MiscVal','MiscFeature','3SsnPorch','LowQualFinSF','Street',\n",
    "                                    'Condition2','RoofMatl','Heating','PoolQC']\n",
    "def dropCols(data, colsToDrop):\n",
    "    return data.drop(colsToDrop, axis=1)\n",
    "\n",
    "\n",
    "cleaned.train = dropCols(cleaned.train, colsToDrop)\n",
    "cleaned.test = dropCols(cleaned.test, colsToDrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in trainNumCols:\n",
    "#     print(col, '-' ,kurtosis(cleaned.train[col], bias = False, fisher=True))\n",
    "#     if kurtosis(cleaned.train[col], bias = False, fisher=True) > 5:\n",
    "#         kurtosis(cleaned.train[col], bias = False, fisher=True)\n",
    "\n",
    "def logTransform(data, colsToTransform):\n",
    "    for col in colsToTransform:\n",
    "        if col == 'TotalBsmtSF':\n",
    "            data[col] = np.log1p(data[col])**5\n",
    "        elif col == 'SalePrice':\n",
    "            try:\n",
    "                data['SalePrice'] = np.log1p(data['SalePrice'])\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            data[col] = np.log1p(data[col])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToTransform = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF',\n",
    "                   '1stFlrSF', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                   '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal','SalePrice']\n",
    "\n",
    "colsToTransform = np.setdiff1d(colsToTransform, colsToDrop)\n",
    "\n",
    "logTransform(cleaned.train, colsToTransform)\n",
    "logTransform(cleaned.test, colsToTransform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummify Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordCols = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n",
    "            'KitchenAbvGr','TotRmsAbvGrd', 'Fireplaces', 'GarageCars','MoSold', 'YrSold','ExterQual','ExterCond',\n",
    "            'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','FireplaceQu','GarageFinish','GarageQual',\n",
    "            'GarageCond','PoolQC','Fence','LandSlope']\n",
    "\n",
    "ordCols = np.setdiff1d(ordCols, colsToDrop)\n",
    "cleaned.ordinalEncode(ordCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained, tested = cleaned.dummify(['ExternalQual','ExternalCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1'\n",
    "                                  'BsmtFinType2','HeatingQC','KitchenQual','FireplaceQu','GarageFinish','GarageQual'\n",
    "                                  'GarageCond','PoolQC','FenceQC','LandSlope','Functional'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allZeroCols = trained.columns[(trained == 0).all()].to_list() + tested.columns[(tested == 0).all()].to_list()\n",
    "trained = trained.drop(allZeroCols, axis=1)\n",
    "tested = tested.drop(allZeroCols, axis=1)\n",
    "\n",
    "X = trained.loc[:, trained.columns != 'SalePrice']\n",
    "y = trained['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best(k):\n",
    "    k_best = SelectKBest(f_regression, k=k).fit(X, y)\n",
    "    X[X.columns[k_best.get_support()]]\n",
    "\n",
    "    k_best_scores = zip(X.columns, k_best.scores_)\n",
    "    sorted_coef_importance = sorted(list(k_best_scores),key= lambda x: x[1],reverse=True)\n",
    "    sorted_coef_importance\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(13, 9))\n",
    "    sns.barplot([x[0] for x in sorted_coef_importance[:k]], [x[1] for x in sorted_coef_importance[:k]])\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_k_best(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dummy_cols = [col for col in X.columns if 'Dummy' not in col]\n",
    "f, ax = plt.subplots(figsize=(30, 12))\n",
    "corr = X[non_dummy_cols].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_tri = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool))\n",
    "upper_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "mostCorrelatedFeat = get_top_abs_correlations(corr, 500)\n",
    "mostCorrelatedFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = set()\n",
    "for pair in mostCorrelatedFeat.index[mostCorrelatedFeat > 0.9]:\n",
    "    corr1 = X[pair[0]].corr(y)\n",
    "    corr2 = X[pair[1]].corr(y)\n",
    "            \n",
    "    if abs(corr1) > abs(corr2):\n",
    "        dropped.add(pair[1])\n",
    "    else:\n",
    "        dropped.add(pair[0])\n",
    "\n",
    "        \n",
    "mostCorrelatedFeat.index[mostCorrelatedFeat > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVars = set()\n",
    "for i in range(len(mostCorrelatedFeat.index[mostCorrelatedFeat > 0.9])):\n",
    "    for j in range(2):\n",
    "        allVars.add(mostCorrelatedFeat.index[mostCorrelatedFeat > 0.9][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = allVars - dropped\n",
    "remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.loc[:, X.columns.difference(dropped)]\n",
    "#X = X.drop(['GarageCars','PoolQC','1stFlrSF','ExterQual','YearRemodAdd'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split_indices = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    split_indices.append([train_index, test_index])\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoringOptions = [None, make_scorer(mean_squared_log_error)]\n",
    "gridScoring = scoringOptions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "params = {'n_estimators': [100,200,300,500],\n",
    "          'max_depth':[2,3,4,5],\n",
    "          'max_features':['sqrt'],\n",
    "          'subsample':[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3], \n",
    "          'loss':['ls']}\n",
    "\n",
    "gridGbr = GridSearchCV(model, param_grid=params, cv=5, scoring=gridScoring)\n",
    "gridGbr.fit(X, y)\n",
    "print(gridGbr.cv_results_)\n",
    "print(gridGbr.best_params_)\n",
    "print(gridGbr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportance(num, cols, features_importances_, sort):\n",
    "    \n",
    "    feature_importances = zip(cols, features_importances_)\n",
    "    sorted_importance = sorted(list(feature_importances),key= lambda x: abs(x[1]),reverse=False if sort == 'ascending' else True)\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(13, 9))\n",
    "    sns.barplot([x[0] for x in sorted_importance[:num]], [x[1] for x in sorted_importance[:num]])\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    return sorted_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFeatureImportance(20, X.columns.to_list(), gridGbr.best_estimator_.feature_importances_, sort='descending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_indices = split_indices[2][0]\n",
    "# test_indices = split_indices[2][1]\n",
    "# train_data = X.iloc[test_indices]\n",
    "# predictions = grid.predict(train_data)\n",
    "# actuals = y.iloc[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_results = pd.DataFrame(predictions, actuals).reset_index().rename(columns={'SalePrice':'Predictions',0:'Actuals'})\n",
    "# split_results['AbsDifference'] = abs(split_results['Predictions'] - split_results['Actuals'])\n",
    "# split_results['Difference'] = split_results['Predictions'] - split_results['Actuals']\n",
    "# split_results_sorted = split_results.sort_values(by='AbsDifference', ascending=False)\n",
    "# split_results_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_sorted = train_data.iloc[split_results_sorted.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger_errors = train_data_sorted.iloc[:int(len(train_data_sorted)/2)]\n",
    "# smaller_errors = train_data_sorted.iloc[int(len(train_data_sorted)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger_errors.mean()[['TotalIndoorSF','OverallQual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller_errors.mean()[['TotalIndoorSF','OverallQual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_results_sorted.iloc[:int(len(split_results_sorted)/2)]['Actuals'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_results_sorted.iloc[int(len(split_results_sorted)/2):]['Actuals'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger_errors.iloc[0,:60] - train_data_sorted.mean()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_results_sorted.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(trained.loc[:, trained.columns != 'SalePrice'])\n",
    "X_Scaled = pd.DataFrame(X_Scaled, columns = trained.columns[trained.columns != 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "params = {'alpha':[0.1,1,10,50,75,100,1000,2000]}\n",
    "gridRidge = GridSearchCV(model, param_grid=params, cv=5, scoring=gridScoring)\n",
    "gridRidge.fit(X_Scaled, y)\n",
    "print(gridRidge.cv_results_)\n",
    "print(gridRidge.best_params_)\n",
    "print(gridRidge.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvals = stats.coef_pval(gridRidge.best_estimator_, X_Scaled, y)\n",
    "pvals_sorted = getFeatureImportance(30, X_Scaled.columns, pvals, sort='ascending')\n",
    "pvals_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefMagSorted = getFeatureImportance(30, X_Scaled.columns, gridRidge.best_estimator_.coef_, sort='descending')\n",
    "coefMagSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_subset = [val[0] for val in pvals_sorted if val[1] < 0.05]\n",
    "col_subset = [val[0] for val in coefMagSorted[:51]]\n",
    "gridRidge = GridSearchCV(model, param_grid=params, cv=5, scoring=gridScoring)\n",
    "gridRidge.fit(X_Scaled[col_subset], y)\n",
    "print(gridRidge.cv_results_)\n",
    "print(gridRidge.best_params_)\n",
    "print(gridRidge.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.summary(gridRidge.best_estimator_, X_Scaled[col_subset], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso()\n",
    "params = {'alpha':[0.005,0.006,0.0007,0.0008,0.001,0.01,0.1,1,10]}\n",
    "gridLasso = GridSearchCV(model, param_grid=params, cv=5, scoring=gridScoring)\n",
    "gridLasso.fit(X_Scaled, y)\n",
    "print(gridLasso.cv_results_)\n",
    "print(gridLasso.best_params_)\n",
    "print(gridLasso.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = stats.coef_pval(gridLasso.best_estimator_, X_Scaled, y)\n",
    "pvals_sorted = getFeatureImportance(30, X_Scaled.columns, pvals, sort='ascending')\n",
    "pvals_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefMagSorted = getFeatureImportance(30, X_Scaled.columns, gridLasso.best_estimator_.coef_, sort='descending')\n",
    "coefMagSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.summary(gridLasso.best_estimator_, X_Scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()\n",
    "params = {'kernel':['linear'],'C':[0.01,0.1],'epsilon':[0.001,0.01,0.1,1]}\n",
    "gridSVR = GridSearchCV(model, param_grid=params, cv=5, scoring=gridScoring)\n",
    "gridSVR.fit(X_Scaled, y)\n",
    "print(gridSVR.cv_results_)\n",
    "print(gridSVR.best_params_)\n",
    "print(gridSVR.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_scaled = scaler.transform(tested)\n",
    "tested_scaled = pd.DataFrame(tested_scaled, columns = tested.columns)\n",
    "\n",
    "gbr_predictions = gridGbr.predict(tested)\n",
    "ridge_predictions = gridRidge.predict(tested_scaled[col_subset])\n",
    "lasso_predictions = gridLasso.predict(tested_scaled)\n",
    "svr_predictions = gridSVR.predict(tested_scaled)\n",
    "\n",
    "gbr_predictions = pd.Series(np.exp(np.array(gbr_predictions)))\n",
    "ridge_predictions = pd.Series(np.exp(np.array(ridge_predictions)))\n",
    "lasso_predictions = pd.Series(np.exp(np.array(lasso_predictions)))\n",
    "svr_predictions = pd.Series(np.exp(np.array(svr_predictions)))\n",
    "\n",
    "results = pd.concat([tested.reset_index()['Id'], pd.concat([gbr_predictions, ridge_predictions, lasso_predictions, svr_predictions], axis=1)],axis=1)\n",
    "\n",
    "final_pred_log_avg = np.exp((np.log(results[0]) + np.log(results[1]) + np.log(results[2]) + np.log(results[3]))/4)\n",
    "final_pred_log_avg = pd.DataFrame(final_pred_log_avg, columns=['SalePrice'])\n",
    "final_pred_avg = (results[0] + results[1] + results[2] + results[3])/4\n",
    "final_pred_avg = pd.DataFrame(final_pred_avg, columns=['SalePrice'])\n",
    "\n",
    "results = pd.concat([results, final_pred_log_avg],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[['Id','SalePrice']].to_csv('submission9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
